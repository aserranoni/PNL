\PassOptionsToPackage{dvipsnames}{xcolor}

\documentclass[12pt,twoside,a4paper]{article}
\usepackage{packages}
\title{MAP5747 Programação Não Linear: Exercícios}
\author{Ariel Serranoni}
\date{2º semestre de 2019}

\begin{document}

\maketitle

\section{Lista 1}

\begin{problema}
  Seja \(f\colon\Reals^n\to\Reals\) e sejam
  \(B\subseteq A\subseteq\Reals^n\). Se
 \(\inf_{x\in\Reals^n}f(x)=\alpha\in\Reals\), então
\begin{enumerate}[label=(\roman*)]
\item \(\inf_{x\in A}f(x)\leq\inf_{x\in B}f(x)\);
\item todo minimizador de \(f\) em \(A\) é um minimizador de \(f\)
  em \(B\).
\end{enumerate}
\end{problema}
\begin{proof}[Solução]\hfill
  \begin{enumerate}[label=(\roman*)]
  \item \[\inf_{x\in A} f(x)=
      \min\{\inf_{x\in B}f(x), \inf_{x\in A\setminus B}f(x)\}\leq
      \inf_{x\in B}f(x).\]
  \item Seja \(x\) tal que \(f(x)\leq f(y)\) para cada \(y\in A\). Como
    \(B\subseteq A\) temos que \(f(x)\leq f(y)\) para cada \(y\in B\).
    Logo,
    \(x\) minimiza \(f\) em \(B\).\qedhere
    \end{enumerate}
\end{proof}

\begin{problema}
Exercício 2 - Lista 1
\end{problema}
\begin{proof}[Solução]
  Considere a função \(f\colon\Reals\to\Reals\) dada por
  \(f(x)\coloneqq\exp(x)\). Considere \(\Omega=\Naturals\).
  Então cada ponto \(\bar{x}\in\Omega\) minimiza \(f\) localmente e,
  como \(f\) é injetora temos que \(f(x)\not=f(y)\)
  sempre que \(x\not= y\).\qedhere
\end{proof}

\begin{problema}
Exercício 3 - Lista 1 
\end{problema}
\begin{proof}[Solução]
 
Seja \(\{x_k\}_{k\in\Naturals}\subseteq \Omega\) uma sequência qualquer e
considere a sequência \(\{f(x_k)\}_{k\in\Naturals}\subseteq\Reals\). Como
\(\Omega\) é compacto temos que \(\{x_k\}_{k\in \Naturals}\) admite uma
subsequência convergindo para algum \(x\in\Omega\). Neste caso, segue que
\(\{f(x_k)\}_{k\in\Naturals}\) também admite uma subsequência convergindo
para \(f(x)\). Como \(x\in Omega\) temos que
\(f(x)\in f(\Omega)\). Mostramos
assim que cada sequencia em \(f(\Omega)\) admite uma
subsequência convergindo
para um elemento do próprio \(f(\Omega)\), ou seja, \(f(\Omega)\) é
compacto.

Finalmente, vamos mostrar que \(\alpha\coloneqq\inf_{x\in\Omega}f(x)\in
f(\Omega\)$\backslash$) e
\(\beta\coloneqq\sup_{x\in\Omega}f(x)\in f(\Omega)\).
Como \(f(\Omega)\) é fechado temos que
\(f(\Omega)=\overline{f(\Omega)}\). Portanto é suficiente mostrar que 
\(\alpha,\beta\in\overline{f(\Omega)}\). Seja
\(\varepsilon\in\Reals_{++}\) e note que se
\(\alpha +\varepsilon\mathbb{B}\cap f(\Omega)=\varnothing\)
então \(\inf_{x\in\Omega}f(x)=\inf f(\Omega)\geq\alpha+\varepsilon\).
Isso implica que \(\inf f(\Omega) > \alpha\).
Contradição. [escrevemos analogamente pra \(\beta\)].
\end{proof}

\begin{problema}
Exercício 4 - Lista 1
\end{problema}
\begin{proof}[Solução]
  Considere a função
  \(f\colon\Reals\setminus\{0\}\to\Reals\setminus\{0\}\)
  dada por \(f(x)\coloneqq\frac{1}{x}\). Se consideramos
  \(\Omega=[-1,0)\), temos que \(f\) é contínua em \(\Omega\) e
  que \(\Omega\) é limitado, mas não fechado.
  Portanto não vale o Teorema de Bolzano-Weierstrass e \(f\) não possui
  minimizador, de fato \(f\) é ilimitada em \(\Omega\).
  Similarmente, se \(\Omega=[-1,0]\) temos que \(\Omega\) é compacto
  mas \(f\) não é contínua em \(\Omega\) e tb n vale o teorema.
\end{proof}

\begin{problema}
Exercício 5 - Lista 1   
\end{problema}
\begin{proof}[Solução]
  Como \(f\) é contínua, temos que o conjunto de nível
  dado no enunciado é fechado. Além disso, temos
  por hipótese que o conjunto é limitado. Assim, o
  resultado segue aplicando o exercicio 3.
\end{proof}

\begin{problema}
Exercício 6 - Lista 1  
\end{problema}
\begin{proof}[Solução]
  Seja \(x\in\Reals^n\) e considere o conjunto de nível
  \[N\coloneqq\{y\in\Reals^n\,\colon f(y)\leq f(x)\}.\]
Como \(f\) é contínua temos que \(N\) é fechado. Agora suponha que
\(N\) não é limitado,então existe uma sequencia \(\{y_n\}_{n\in\Naturals}\)
tal que \(\|y_n\|\rightarrow\infty\) mas \(f(y_n)\leq f(x)\) para
todo \(n\in\Naturals\), o que contradiz a hipótese de que
\(f\) é coerciva. Assim concluímos que \(N\) é compacto e
o resultado segue do exercicio 3.
\end{proof}

\begin{problema}
Exercício 7 - Lista 1
\end{problema}
\begin{proof}[Solução]\hfill
  \begin{enumerate}
\item Considere \(f(x)=\exp(x)\) e \(\Omega=\{0\}\).
\item Considere \(f(x)=-x^2\) e \(\Omega=\{0\}\).
\item Considere \(f(x)=x^3\) e \(\Omega=\Reals\).
\item Considere \(f(x)=x^3\) e \(\Omega=\Reals\).\qedhere
\end{enumerate}
\end{proof}


\section{Lista 1 - Old}


\begin{problema}\label{rosenmin}
Exercício 2 - 2.1 do NOCEDAL
\end{problema}
\begin{proof}[Solução]
  Iniciamos calculando uma forma polinomial para a função \(f\).
  Daí, obtemos que
  \begin{equation}\label{rosenfunc}
   f(x_1,x_2)=100x_1^4+x_1^2-2x_1+100x_2^2-200x_1^2x_2+1. 
  \end{equation}
   Além disso, vamos calcular o vetor gradiente e a matriz hessiana de \(f\):
\begin{equation}\label{gradrosen}
  \nabla f(x_1,x_2)=\begin{pmatrix}
    400x_1^3 + 2x_1-400x_1x_2 -2 \\
    200 x_2 - 200x_1^2
  \end{pmatrix}
  \text{ e } \nabla^2 f(x_1,x_2)=\begin{pmatrix}
    1200x_1^2+2-400x_2 & -400x_1 \\
    -400x_1 & 200
    \end{pmatrix}.
\end{equation}
Resolvendo o sistema \(\nabla f(x_1,x_2)=0\) nos dá a solução única
\(x\coloneqq(1,1)^\top\). Feito isso verificamos que
\[\nabla^2f(1,1)=\begin{pmatrix}
    802 & -400 \\
    -400 & 200 \end{pmatrix}\in\mathbb{S}^n_{++}.\]
Assim, concluímos que \(x\) é o único minimizador global de \(f\).
\end{proof}

\begin{problema}
  Exercício 15
\end{problema}
\begin{proof}[Solução]
  
\end{proof}

\begin{problema}
 Exercício 17 - 2.17 da ANA  
 \end{problema}
 \begin{proof}[Solução]
   Fazendo algumas continhas, obtemos facilmente que
   \(f^\prime(x)= 3x^2+2ax+b\) e
  ainda que \(f^{\prime\prime}(x)=6x+2a\). Para que \(0\) seja maximizador
  de
  \(f\), precisamos que \(f^\prime(0) =0\) e que \(f^{\prime\prime}(0)<0\).
  Analogamente para que \(1\) seja minimizador de \(f\) precisamos que
  \(f^\prime(1)=0\) e que \(f^{\prime\prime}(1)>0\). Resolvendo o sistema
  dado por estas equações obtemos a única soluçao \(b=0\) e \(a=-\frac{3}{2}\). 
 \end{proof}

\begin{problema}
Exercício 18
\end{problema}
\begin{proof}[Solução]
  Seja \(\overline{X}\coloneqq\{x\in X\,\colon f(x)=v^\ast\}\), sejam
  \(x_1,x_2\in\overline{X}\), e seja \(\lambda\in [0,1]\). Como \(f\)
  é convexa segue que \[f(\lambda x_1+ (1-\lambda)x_2)\leq\lambda
    f(x_1)+(1-\lambda)f(x_2)=v^\ast.\]
  Mas como \(v^\ast=\inf\{f(x)\,\colon x\in X\}\) também vale que
  \[f(\lambda x_1+ (1-\lambda)x_2)\geq v^\ast.\]
  Assim concluímos que \(f(\lambda x_1+ (1-\lambda)x_2)= v^\ast.\) Portanto,
  segue que \(\lambda x_1 + (1-\lambda)x_2\in\overline{X}\) e logo
  \(\overline{X}\) é convexo.
\end{proof}

\begin{problema}\label{phiconv}
 Exercício 19
\end{problema}
\begin{proof}[Solução]
  Sabemos que \(f\) é convexa se, e só se
  \(\nabla^2f(x)\in\mathbb{S}^n_+\) para cada \(x\in\Reals^n\). Observando
  que \(\phi^{\prime\prime}(\alpha)=d^\top\nabla^2f(x+\alpha d) d\),
  concluímos que \(\phi^{\prime\prime}(\alpha)\geq 0\) para cada
  \(\alpha\in\Reals\). Como este último fato acontece se e só se \(\phi\)
  é convexa, o resultado segue.
\end{proof}

\section{Lista 2 - Old}
\begin{problema}
Exercício 5  
\end{problema}
\begin{proof}[Solução]
  Neste exercício faremos uso das contas feitas no
  Exercício \ref{rosenmin}.
  \begin{enumerate}
  \item Primeiro, veja que \(d=-\nabla f(0,0)=(2,0)^\top\). Neste caso
    segue que
    \begin{align*}
      \phi(\alpha)=f(0+\alpha d)&=f((2\alpha,0)^\top)\\&=
      100((-2\alpha)^2)^2+(1-2\alpha^2)\\&=
      100(16\alpha^4)+4\alpha^2-4\alpha + 1.
    \end{align*}
  \item Primeiro, vamos calcular a direção de Newton. Por definição, segue
    \begin{align*}
      d= (-\nabla^2f((0,0)^\top)^{-1}\nabla f((0,0)^\top)=\begin{pmatrix}
        -\frac{1}{2} & 0 \\ 0 & -\frac{1}{200}\end{pmatrix}\begin{pmatrix}
        -2 \\ 0 
      \end{pmatrix}=\begin{pmatrix}1 \\ 0\end{pmatrix}.
    \end{align*}
    Daí, segue que
    \[f((\alpha,0)^\top)=100((-\alpha)^2)^2+(1-\alpha)^2= 100\alpha^4+\alpha^2-2\alpha+1.\qedhere\]
  \end{enumerate}
\end{proof}

\begin{problema}\label{alphabuscaex}
Exercício 6  
\end{problema}
\begin{proof}[Solução]
  Primeiramente, notamos que \(\nabla f(x)=Ax + b\) e \(\nabla^2 f(x)=A\).
  Como \(A\in\mathbb{S}^n_+\) temos que \(f\) é convexa e portanto pelo
  Exercício \ref{phiconv} temos que
  \(\phi(\alpha)\coloneqq f(x+ \alpha d)\) é convexa para todo
  \(x,d\in\Reals^n\). Assim, podemos calcular o minimizador de phi
  da seguinte maneira:
  \begin{align*}
    &\phi^\prime(\alpha)=0\\&
    \iff\nabla f(x+\alpha d)^\top d=0 \\&
    \iff (A(x+\alpha d) + b)^\top d=0 \\&
    \iff ((Ax+b)^\top +\alpha (Ad)^\top)d=0 \\&
    \iff \nabla f(x)^\top +\alpha d^\top d=0 \\&
    \iff \alpha=-\frac{\nabla f(x)^\top d}{d^\top A d}.\qedhere
   \end{align*}
 \end{proof}

\begin{problema}
   Exercício 10
\end{problema}
\begin{proof}[Solução]
 Primeiramente, note que \(\nabla f(x)=Ax-b\) e que \(x_{t+1}=x_t-\alpha\nabla
 f(x_t)\). Assim, calculando \(\nabla f(x_{t+1})\) em termos de \(\nabla
 f(x_t)\), obtemos que
 \begin{align*}
   \nabla f(x_{t+1})&= A(x_{t+1}) -b\\&
   = A(x_t-\alpha\nabla f(x_t))-b\\&
   = Ax -\alpha A\nabla f(x_t) -b \\&
   = \nabla f(x_t) - \alpha A\nabla f(x_t).
 \end{align*}
 Finalmente, segue que
 \begin{align*}
   \nabla f(x_{t+1})^\top\nabla f(x_t)&
                                        = (\nabla f(x_t) - \alpha A\nabla f(x_t))^\top\nabla f(x_t)\\&
   = \nabla f(x_t)^\top\nabla f(x_t) -\alpha (A\nabla f(x_t))^\top\nabla f(x_t) \\&=\nabla f(x_t)^\top\nabla f(x_t) - \frac{\nabla f(x_t)^\top\nabla f(x_t)\nabla f(x_t)^\top A\nabla f(x_t)}{\nabla f(x_t)^\top A\nabla f(x_t)}\\&= \nabla f(x_t)^\top\nabla f(x_t) - \nabla f(x_t)^\top\nabla f(x_t) \\&= 0.\qedhere
  \end{align*}
\end{proof}

\end{document}
